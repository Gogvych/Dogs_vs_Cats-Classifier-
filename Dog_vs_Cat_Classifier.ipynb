{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d70a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48a6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7c9c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7307f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87511857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e32777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adef016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"D:/Deep_Learning_Dataset/\")\n",
    "image_path = data_path / \"dogs_vs_cats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dbfe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ae449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for target directory\n",
    "\n",
    "target_directory = r'D:\\Deep_Learning_Dataset\\dogs_vs_cats\\train'\n",
    "print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "# Get the class names from the TD\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(image_path / \"train\"))])\n",
    "print(f\"Class names found: {class_names_found}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4595a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9440e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "   \n",
    "    # 1. Class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. Crearte a dictionary of index labels\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59699425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4e4fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = find_classes(target_directory)[0]\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af69d46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb49452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom dataset class function\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) # note: \n",
    "        self.transform = transform\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "    \n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d676283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad2213f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing normalizing transform for the dataset\n",
    "normalize_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((32, 32)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean = (0.5, 0.5, 0.5), \n",
    "                                     std = (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527edc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e10cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_custom = ImageFolderCustom(targ_dir=target_directory, \n",
    "                                      transform=normalize_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68971ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_custom, test_data_custom = random_split(data_custom, [20000, 5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd63b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data_custom), len(test_data_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b991f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining plotting settings\n",
    "plt.rcParams['figure.figsize'] = 14, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62dd1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9715cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_data_custom, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_data_custom, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d00ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting 25 images from the 1st batch \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(\n",
    "  images[:25], normalize=True, padding=1, nrow=5).numpy(), (1, 2, 0)))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb34a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over the training dataset and storing the target class for each sample\n",
    "classes = []\n",
    "for batch_idx, data in enumerate(train_loader, 0):\n",
    "    x, y = data \n",
    "    classes.extend(y.tolist())\n",
    "      \n",
    "#Calculating the unique classes and the respective counts and plotting them\n",
    "unique, counts = np.unique(classes, return_counts=True)\n",
    "names = list(train_data_custom.class_to_idx.keys())\n",
    "plt.bar(names, counts)\n",
    "plt.xlabel(\"Target Classes\")\n",
    "plt.ylabel(\"Number of training instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301de9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN architecture\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.nn.Sequential(\n",
    "            #Input = 3 x 32 x 32, Output = 32 x 32 x 32\n",
    "            torch.nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, padding = 1), \n",
    "            torch.nn.ReLU(),\n",
    "            #Input = 32 x 32 x 32, Output = 32 x 16 x 16\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "  \n",
    "            #Input = 32 x 16 x 16, Output = 64 x 16 x 16\n",
    "            torch.nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            #Input = 64 x 16 x 16, Output = 64 x 8 x 8\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "              \n",
    "            #Input = 64 x 8 x 8, Output = 64 x 8 x 8\n",
    "            torch.nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            #Input = 64 x 8 x 8, Output = 64 x 4 x 4\n",
    "            torch.nn.MaxPool2d(kernel_size=2),\n",
    "  \n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(64*4*4, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10)\n",
    "        )\n",
    "  \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94662d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81708f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the appropriate training device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = CNN().to(device)\n",
    "  \n",
    "#Defining the model hyper parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "  \n",
    "#Training process begins\n",
    "train_loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}:', end = ' ')\n",
    "    train_loss = 0\n",
    "      \n",
    "    #Iterating over the training dataset in batches\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "          \n",
    "        #Extracting images and target labels for the batch being iterated\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "  \n",
    "        #Calculating the model output and the cross entropy loss\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "  \n",
    "        #Updating weights according to calculated loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "      \n",
    "    #Printing loss for each epoch\n",
    "    train_loss_list.append(train_loss/len(train_loader))\n",
    "    print(f\"Training loss = {train_loss_list[-1]}\")   \n",
    "      \n",
    "#Plotting loss for all epochs\n",
    "plt.plot(range(1,num_epochs+1), train_loss_list)\n",
    "plt.xlabel(\"Number of epochs\")\n",
    "plt.ylabel(\"Training loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c491159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd43612",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc=0\n",
    "model.eval()\n",
    "  \n",
    "with torch.no_grad():\n",
    "    #Iterating over the training dataset in batches\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "          \n",
    "        images = images.to(device)\n",
    "        y_true = labels.to(device)\n",
    "          \n",
    "        #Calculating outputs for the batch being iterated\n",
    "        outputs = model(images)\n",
    "          \n",
    "        #Calculated prediction labels from models\n",
    "        _, y_pred = torch.max(outputs.data, 1)\n",
    "          \n",
    "        #Comparing predicted and true labels\n",
    "        test_acc += (y_pred == y_true).sum().item()\n",
    "      \n",
    "    print(f\"Test set accuracy = {100 * test_acc / len(test_data_custom)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c88683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed73a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating predictions for 'num_images' amount of images from the last batch of test set\n",
    "num_images = 5\n",
    "y_true_name = [names[y_true[idx]] for idx in range(num_images)] \n",
    "y_pred_name = [names[y_pred[idx]] for idx in range(num_images)] \n",
    "  \n",
    "#Generating the title for the plot\n",
    "title = f\"Actual labels: {y_true_name}, Predicted labels: {y_pred_name}\"\n",
    "  \n",
    "#Finally plotting the images with their actual and predicted labels in the title\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(images[:num_images].cpu(), normalize=True, padding=1).numpy(), (1, 2, 0)))\n",
    "plt.title(title)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220a1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d35711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b81f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
